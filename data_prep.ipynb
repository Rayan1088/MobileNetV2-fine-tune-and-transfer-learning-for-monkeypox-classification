{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c8fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tqdm in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: scipy in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: colorama in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\mobilenetv2\\mobilenetv2-fine-tune-and-transfer-learning-for-monkeypox-classification\\cvenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tqdm pillow scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78df83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "import random\n",
    "import logging\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71faaa01",
   "metadata": {},
   "source": [
    "# **Analyze The Dataset :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebfec305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(dir):\n",
    "    \n",
    "    cls_counts={}\n",
    "    img_ext=('.jpg', '.jpeg', '.png')\n",
    "    \n",
    "    if not os.path.exists(dir):\n",
    "        print(f\"Error!!-Directory [{dir}] can not found.\")\n",
    "        return None\n",
    "    \n",
    "    for cls_name in os.listdir(dir):\n",
    "        cls_path = os.path.join(dir, cls_name)    \n",
    "        \n",
    "        if os.path.isdir(cls_path):\n",
    "            try:\n",
    "                img_files=[f for f in os.listdir(cls_path) if f.lower().endswith(img_ext)]\n",
    "                cls_counts[cls_name]=len(img_files)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred during get the fils from the directory [{dir}]: {e}\")\n",
    "                cls_counts[cls_name]=0\n",
    "                \n",
    "    total_imgs=sum(cls_counts.values())\n",
    "    print(f\"Total Images : {total_imgs}\")\n",
    "    \n",
    "    for cls_name, count in sorted(cls_counts.items()):\n",
    "        percentage =(count/total_imgs*100) if total_imgs>0 else 0\n",
    "        print(f\"[{cls_name}] : {count} Images, [{percentage:.1f}%]\")\n",
    "    \n",
    "    return cls_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcdfc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images : 755\n",
      "[Chickenpox] : 75 Images, [9.9%]\n",
      "[Cowpox] : 66 Images, [8.7%]\n",
      "[HFMD] : 161 Images, [21.3%]\n",
      "[Healthy] : 114 Images, [15.1%]\n",
      "[Measles] : 55 Images, [7.3%]\n",
      "[Monkeypox] : 284 Images, [37.6%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Chickenpox': 75,\n",
       " 'Cowpox': 66,\n",
       " 'Healthy': 114,\n",
       " 'HFMD': 161,\n",
       " 'Measles': 55,\n",
       " 'Monkeypox': 284}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_dataset(dir=\"F:/MobileNetV2/Dataset/Skin diseases data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29be7c",
   "metadata": {},
   "source": [
    "# **Balance The Classes Using Data Augmentation :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9184582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(input_dir, output_dir, target_images, save_format, random_seed):\n",
    "   \n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Error!!-Directory [{input_dir}] cannot be found.\")\n",
    "        return None    \n",
    "    \n",
    "    # For reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "    img_ext = ('.jpg', '.jpeg', '.png')\n",
    "    \n",
    "    # Create data generator \n",
    "    data_gen= ImageDataGenerator(rotation_range=5,\n",
    "                                 horizontal_flip=False,\n",
    "                                 vertical_flip=False,\n",
    "                                 zoom_range=0.1,\n",
    "                                 brightness_range=[0.95, 1.05],\n",
    "                                 width_shift_range=0.05,\n",
    "                                 height_shift_range=0.05,\n",
    "                                 fill_mode='nearest' # fill new pixels with nearest value                                   \n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        img_files = [f for f in os.listdir(input_dir) if f.lower().endswith(img_ext)]\n",
    "        current_images = len(img_files)\n",
    "        print(f\"Found [{current_images}] images in [{input_dir}] path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during getting the fils from the directory [{input_dir}]: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Check if any images were found \n",
    "    if current_images == 0:\n",
    "        print(f\"No images found in directory [{input_dir}].\")\n",
    "        return None\n",
    "    \n",
    "    # Check augmentation is needed or not \n",
    "    if current_images >= target_images:\n",
    "        print(f\"Warning!!-Current images [{current_images}] >= target [{target_images}], So no augmentation needed.\")\n",
    "        return 0\n",
    "    \n",
    "    # Create output directory \n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Output directory created or verified : [{output_dir}].\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during create the directory [{output_dir}]: {e}\")\n",
    "        return None\n",
    "        \n",
    "    # Calculate images to generate\n",
    "    imgs_to_gen = target_images - current_images\n",
    "    print(f\"Need to generate [{imgs_to_gen}] additional images to balance the dataset.\")\n",
    "    \n",
    "    # Calculate distribution of augmented images per original image \n",
    "    imgs_per_original = imgs_to_gen // current_images \n",
    "    remainder = imgs_to_gen % current_images\n",
    "    \n",
    "    print(f\"Generating [{imgs_per_original}] images per original, with [{remainder}] images getting one extra.\")\n",
    "    total_generated = 0\n",
    "    \n",
    "    # Process each image from directory\n",
    "    for idx, img_name in enumerate(tqdm(img_files, desc=\"Augmenting images\")):\n",
    "        try:\n",
    "            img_path = os.path.join(input_dir, img_name)\n",
    "            \n",
    "            # load and preprocess image\n",
    "            img=load_img(img_path)\n",
    "            img_array=img_to_array(img)\n",
    "            img_array=img_array.reshape((1,) + img_array.shape)\n",
    "            \n",
    "            # calculate how many augmented images to generate for this original\n",
    "            target_per_img = imgs_per_original + (1 if idx < remainder else 0)\n",
    "            \n",
    "            # skip if no images needed for this original\n",
    "            if target_per_img == 0:\n",
    "                continue\n",
    "            \n",
    "            #Generate augmented images\n",
    "            generated_count = 0\n",
    "            base_name=os.path.splitext(img_name)[0]\n",
    "            \n",
    "            # Create a generator and iterate through it\n",
    "            aug_iter = data_gen.flow(\n",
    "                img_array,batch_size=1,\n",
    "                save_to_dir=output_dir,\n",
    "                save_prefix=f'aug_{base_name}_',\n",
    "                save_format=save_format\n",
    "            ) \n",
    "\n",
    "            # Generate the required number of augmented images \n",
    "            for i in range(target_per_img):\n",
    "                try:\n",
    "                    next(aug_iter) # Generate one augmented image\n",
    "                    generated_count += 1\n",
    "                    total_generated += 1\n",
    "                \n",
    "                except StopIteration:\n",
    "                    print(f\"Warning!!-Generator exhausted for [{img_name}] after [{generated_count}] images.\")\n",
    "                    break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during processing [{img_name}]: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "    print(f\"Augmentation complete! Generated [{total_generated}] new images.\")\n",
    "    print(f\"Total images now [{current_images + total_generated}] new images.\")  \n",
    "    \n",
    "    return total_generated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a7d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation multiple classes together \n",
    "def multi_aug_classes(input_dir, output_dir, class_targets, save_format, random_seed):\n",
    "    \n",
    "    for class_name, target_count in class_targets.items():\n",
    "        input_path = os.path.join(input_dir, class_name)\n",
    "        output_path = os.path.join(output_dir, class_name)\n",
    "        \n",
    "        print(f\"Processing class: [{class_name}]\")\n",
    "        \n",
    "        try:\n",
    "            augmentation(input_dir = input_path,\n",
    "                         output_dir = output_path,\n",
    "                         target_images = target_count,\n",
    "                         save_format = save_format,\n",
    "                         random_seed = random_seed)\n",
    "            \n",
    "            # Verify results (Save or Not)\n",
    "            img_ext = ('.jpg', '.jpeg', '.png')\n",
    "            if os.path.exists(output_path):\n",
    "                final_count = len([f for f in os.listdir(output_path) if f.lower().endswith(img_ext)])\n",
    "                print(f\"Verification: [{final_count}] files in output directory.\")\n",
    "            else:\n",
    "                print(f\"Warning!!-Output directory [{output_path}] does not exist for class [{class_name}]\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process class: [{class_name}]: {str(e)}\")\n",
    "            continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd4d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution for classes\n",
    "# Since 'Monkeypox' class has 284 images \n",
    "class_targets = {'Chickenpox': 284,\n",
    "                 'Cowpox': 284,\n",
    "                 'Healthy': 284,\n",
    "                 'HFMD': 284,\n",
    "                 'Measles': 284,     \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "254f8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: [Chickenpox]\n",
      "Found [75] images in [F:/MobileNetV2/Dataset/Skin diseases data\\Chickenpox] path.\n",
      "Output directory created or verified : [F:/MobileNetV2/Dataset/augmented images\\Chickenpox].\n",
      "Need to generate [209] additional images to balance the dataset.\n",
      "Generating [2] images per original, with [59] images getting one extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images:   0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 75/75 [00:05<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete! Generated [209] new images.\n",
      "Total images now [284] new images.\n",
      "Verification: [209] files in output directory.\n",
      "Processing class: [Cowpox]\n",
      "Found [66] images in [F:/MobileNetV2/Dataset/Skin diseases data\\Cowpox] path.\n",
      "Output directory created or verified : [F:/MobileNetV2/Dataset/augmented images\\Cowpox].\n",
      "Need to generate [218] additional images to balance the dataset.\n",
      "Generating [3] images per original, with [20] images getting one extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 66/66 [00:06<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete! Generated [218] new images.\n",
      "Total images now [284] new images.\n",
      "Verification: [218] files in output directory.\n",
      "Processing class: [Healthy]\n",
      "Found [114] images in [F:/MobileNetV2/Dataset/Skin diseases data\\Healthy] path.\n",
      "Output directory created or verified : [F:/MobileNetV2/Dataset/augmented images\\Healthy].\n",
      "Need to generate [170] additional images to balance the dataset.\n",
      "Generating [1] images per original, with [56] images getting one extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 114/114 [00:04<00:00, 23.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete! Generated [170] new images.\n",
      "Total images now [284] new images.\n",
      "Verification: [170] files in output directory.\n",
      "Processing class: [HFMD]\n",
      "Found [161] images in [F:/MobileNetV2/Dataset/Skin diseases data\\HFMD] path.\n",
      "Output directory created or verified : [F:/MobileNetV2/Dataset/augmented images\\HFMD].\n",
      "Need to generate [123] additional images to balance the dataset.\n",
      "Generating [0] images per original, with [123] images getting one extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 161/161 [00:16<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete! Generated [123] new images.\n",
      "Total images now [284] new images.\n",
      "Verification: [123] files in output directory.\n",
      "Processing class: [Measles]\n",
      "Found [55] images in [F:/MobileNetV2/Dataset/Skin diseases data\\Measles] path.\n",
      "Output directory created or verified : [F:/MobileNetV2/Dataset/augmented images\\Measles].\n",
      "Need to generate [229] additional images to balance the dataset.\n",
      "Generating [4] images per original, with [9] images getting one extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 55/55 [00:05<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete! Generated [229] new images.\n",
      "Total images now [284] new images.\n",
      "Verification: [229] files in output directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Call and run the multi class augmentation funtion\n",
    "multi_aug_classes(input_dir='F:/MobileNetV2/Dataset/Skin diseases data',\n",
    "                  output_dir='F:/MobileNetV2/Dataset/augmented images', \n",
    "                  class_targets=class_targets,\n",
    "                  save_format='.jpg', \n",
    "                  random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383afc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images : 1704\n",
      "[Chickenpox] : 284 Images, [16.7%]\n",
      "[Cowpox] : 284 Images, [16.7%]\n",
      "[HFMD] : 284 Images, [16.7%]\n",
      "[Healthy] : 284 Images, [16.7%]\n",
      "[Measles] : 284 Images, [16.7%]\n",
      "[Monkeypox] : 284 Images, [16.7%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Chickenpox': 284,\n",
       " 'Cowpox': 284,\n",
       " 'Healthy': 284,\n",
       " 'HFMD': 284,\n",
       " 'Measles': 284,\n",
       " 'Monkeypox': 284}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze dataset after agumentation \n",
    "analyze_dataset(dir=\"F:/MobileNetV2/Dataset/Skin diseases data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c542f23",
   "metadata": {},
   "source": [
    "# **Split Raw Image Data Into Train & Vaild :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae4b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_dir, output_dir, train_ratio=0.8, seed=42):\n",
    "    if not input_dir or not os.path.exists(input_dir):\n",
    "        print(\"Input directory can not found.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Input directory found sucessfully and continue the process.\")\n",
    "    \n",
    "    random.seed(seed)\n",
    "    input_dir=Path(input_dir)\n",
    "    output_dir=Path(output_dir)\n",
    "    total_files=0\n",
    "    processed_files=0\n",
    "    \n",
    "    # Create the output directory\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Iterate through class directories\n",
    "    for cls_dir in input_dir.iterdir():\n",
    "        if cls_dir.is_dir():\n",
    "            img_ext = ['*.jpg', '*.jpeg', '*.png']\n",
    "            imgs=[]\n",
    "            \n",
    "            for ext in img_ext:\n",
    "                imgs.extend(cls_dir.glob(ext))\n",
    "                imgs.extend(cls_dir.glob(ext.upper())) # For upper case ext.\n",
    "            \n",
    "            if not imgs:\n",
    "                print(f\"Warning!!-No image files found in [{cls_dir.name}].\")\n",
    "                continue \n",
    "            \n",
    "            print(f\"Processing class [{cls_dir.name}] with [{len(imgs)}] images.\")\n",
    "            total_files += len(imgs)\n",
    "\n",
    "            # Shuffle images randomly\n",
    "            random.shuffle(imgs)\n",
    "            \n",
    "            # calculate split index\n",
    "            split_idx=int(len(imgs) * train_ratio)\n",
    "            train_imgs=imgs[:split_idx]\n",
    "            val_imgs=imgs[split_idx:]\n",
    "            \n",
    "            print(f\"Train - [{len(train_imgs)}] , Validation - [{len(val_imgs)}].\")\n",
    "            \n",
    "            # Copy files to output directories\n",
    "            for split, split_imgs in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "                target_dir= output_dir / split / cls_dir.name\n",
    "                target_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                for img_path in split_imgs:\n",
    "                    try:\n",
    "                        shutil.copy(img_path, target_dir / img_path.name)\n",
    "                        processed_files +=1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred during copying [{img_path.name}]: {e}\")\n",
    "                        \n",
    "    print(f\"Dataset split completed. Processed [{processed_files}/{total_files}] files.\")\n",
    "    \n",
    "    return processed_files == total_files\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6c647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input directory found sucessfully and continue the process.\n",
      "Processing class [Chickenpox] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Processing class [Cowpox] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Processing class [Healthy] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Processing class [HFMD] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Processing class [Measles] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Processing class [Monkeypox] with [568] images.\n",
      "Train - [454] , Validation - [114].\n",
      "Dataset split completed. Processed [3408/3408] files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset(input_dir=\"F:/MobileNetV2/Dataset/Skin diseases data\",\n",
    "              output_dir=\"F:/MobileNetV2/Dataset/Skin diseases splited Dataset\",\n",
    "              train_ratio=0.8, \n",
    "              seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
